{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets import ImageNet\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "\n",
    "import torchvision\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## CARS #########\n",
    "f1  = open(\"class_string.txt\", \"r\").read().split(\"\\n\")\n",
    "f2  = open(\"fname_string.txt\", \"r\").read().split(\"\\n\")\n",
    "f3 = open(\"bbox.txt\", \"r\").read().split(\"\\n\")\n",
    "totbbox = []\n",
    "for ind, line in enumerate(f3):\n",
    "    f1[ind] = int(f1[ind])\n",
    "    bbox = line.split(\"\\t\") # x1,y1,x2,y2\n",
    "    bbox[0] = float(bbox[0])\n",
    "    bbox[1] = float(bbox[1])\n",
    "    bbox[2] = float(bbox[2])\n",
    "    bbox[3] = float(bbox[3])\n",
    "    totbbox.append(bbox)\n",
    "fin_list = []\n",
    "for i in range(len(f2)):\n",
    "    fin_list.append([f2[i],f1[i],totbbox[i][0],totbbox[i][1],totbbox[i][2],totbbox[i][3]])\n",
    "df = pd.DataFrame(fin_list, columns=['image_id','labels', 'x0','y0','x1','y1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## License plates ##########\n",
    "f4 = open(\"lp_bb.txt\", \"r\").read().split(\"\\n\")\n",
    "totbbox = []\n",
    "for line in f4:\n",
    "    if(line==\"\"):\n",
    "        break\n",
    "    bbox = line.split(\"\\t\") # x1,y1,x2,y2\n",
    "    bbox[0] = float(bbox[0])\n",
    "    bbox[1] = float(bbox[1])\n",
    "    bbox[2] = float(bbox[2])\n",
    "    bbox[3] = float(bbox[3])\n",
    "    totbbox.append(bbox)\n",
    "fin_list = []\n",
    "for i in range(len(f4)-1):\n",
    "    fin_list.append([\"Cars{}.png\".format(i),1,totbbox[i][0],totbbox[i][1],totbbox[i][2],totbbox[i][3]])\n",
    "df_LP = pd.DataFrame(fin_list[:300], columns=['image_id','labels', 'x0','y0','x1','y1'])\n",
    "df_LP_eval = pd.DataFrame(fin_list[300:350], columns=['image_id','labels', 'x0','y0','x1','y1'])\n",
    "df_LP_test = pd.DataFrame(fin_list[350:], columns=['image_id','labels', 'x0','y0','x1','y1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Full_set ##########\n",
    "df_tot=df.append(df_LP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### TEST_SET ########\n",
    "ft = open(\"test.txt\", \"r\").read().split(\"\\n\")\n",
    "totbbox = []\n",
    "fin_list = []\n",
    "for ind, line in enumerate(ft):\n",
    "    line = line.split(\"\\t\")\n",
    "    if(int(line[6]) == 1):\n",
    "        line[5] = int(line[5])\n",
    "        bbox = line[1:5] # x1,y1,x2,y2\n",
    "        bbox[0] = float(bbox[0])\n",
    "        bbox[1] = float(bbox[1])\n",
    "        bbox[2] = float(bbox[2])\n",
    "        bbox[3] = float(bbox[3])\n",
    "        totbbox.append(bbox)\n",
    "        fin_list.append([line[0],line[5],bbox[0],bbox[1],bbox[2],bbox[3]])\n",
    "random.shuffle(fin_list)    \n",
    "df_test = pd.DataFrame(fin_list[0:7000], columns=['image_id','labels', 'x0','y0','x1','y1'])\n",
    "df_eval = pd.DataFrame(fin_list[7001:], columns=['image_id','labels', 'x0','y0','x1','y1'])\n",
    "df_test_full = df_test.append(df_LP_test)\n",
    "df_eval_full = df_eval.append(df_LP_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transforms= None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.df = df\n",
    "        self.image_ids = self.df['image_id']\n",
    "        self.image_dir = image_dir\n",
    "        self.labels = self.df['labels']\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        records = self.df[self.df[\"image_id\"]==image_id]\n",
    "        \n",
    "        img = Image.open(self.image_dir/image_id).convert(\"RGB\")\n",
    "        img = transforms.ToTensor()(img)\n",
    "        \n",
    "        boxes = records[[\"x0\",\"y0\", \"x1\", \"y1\"]].values\n",
    "        boxes = torch.tensor(boxes)\n",
    "        boxes = boxes.type(torch.FloatTensor)\n",
    "        labels = records[\"labels\"].values\n",
    "        labels = torch.tensor(labels)\n",
    "        labels = labels.type(torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        \n",
    "        return img, target\n",
    "                            \n",
    "                                  \n",
    "                                  \n",
    "    def __len__(self):\n",
    "        return self.image_ids.shape[0]\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))  \n",
    "        \n",
    "dataset = CarDataset(df, Path.cwd() / \"cars_train\") #\"train_all\"\n",
    "dataset_LP = CarDataset(df_LP,Path.cwd() / \"LPtrain/images\")        \n",
    "dataloaded = DataLoader(dataset, batch_size=1, collate_fn = collate_fn)  \n",
    "dataloaded_LP = DataLoader(dataset_LP, batch_size=1, collate_fn = collate_fn)\n",
    "\n",
    "dataset_LP_eval = CarDataset(df_LP_eval,Path.cwd() / \"LPtrain/images\")\n",
    "dataset_LP_test = CarDataset(df_LP_test,Path.cwd() / \"LPtrain/images\")   \n",
    "dataloaded_LP_eval = DataLoader(dataset_LP_eval, batch_size=1, collate_fn = collate_fn)\n",
    "dataloaded_LP_test = DataLoader(dataset_LP_test, batch_size=1, collate_fn = collate_fn)\n",
    "\n",
    "dataset_tot = CarDataset(df_tot, Path.cwd() / \"tot_train\")\n",
    "dataloaded_tot = DataLoader(dataset_tot, batch_size=1, collate_fn = collate_fn, shuffle = True)\n",
    "\n",
    "\n",
    "dataset_tot_eval = CarDataset(df_eval_full, Path.cwd() / \"eval_test\")\n",
    "dataset_tot_test = CarDataset(df_test_full, Path.cwd() / \"eval_test\")\n",
    "dataloaded_tot_eval = DataLoader(dataset_tot_eval, batch_size=1, collate_fn = collate_fn, shuffle = True)\n",
    "dataloaded_tot_test = DataLoader(dataset_tot_test, batch_size=1, collate_fn = collate_fn, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CAR ########\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "model = models.detection.fasterrcnn_resnet50_fpn(pretrained = True, pretrained_backbone = True)#, num_classes = 197)\n",
    "\n",
    "classes = 197\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features,classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "load_old_model = False\n",
    "\n",
    "if(load_old_model):\n",
    "    model.load_state_dict(torch.load(Path.cwd() / \"one_epoch\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### License plate ########\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "model_LP = models.detection.fasterrcnn_resnet50_fpn(pretrained = True, pretrained_backbone = True)#, num_classes = 197)\n",
    "\n",
    "classes = 2\n",
    "in_features = model_LP.roi_heads.box_predictor.cls_score.in_features\n",
    "model_LP.roi_heads.box_predictor = FastRCNNPredictor(in_features,classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_LP.to(device)\n",
    "\n",
    "load_old_model_LP = False\n",
    "\n",
    "if(load_old_model_LP):\n",
    "    model_LP.load_state_dict(torch.load(Path.cwd() / \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Tot set ########\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "model_tot = models.detection.fasterrcnn_resnet50_fpn(pretrained = True, pretrained_backbone = True)#, num_classes = 197)\n",
    "\n",
    "classes = 198\n",
    "in_features = model_tot.roi_heads.box_predictor.cls_score.in_features\n",
    "model_tot.roi_heads.box_predictor = FastRCNNPredictor(in_features,classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_tot.to(device)\n",
    "\n",
    "load_old_model_tot = False\n",
    "\n",
    "if(load_old_model_tot):\n",
    "    model_tot.load_state_dict(torch.load(Path.cwd() / \"Model_tot_epoch_19\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, df):\n",
    "    model.eval()\n",
    "    n=0\n",
    "    with torch.no_grad():\n",
    "        for b_x, b_y in df:\n",
    "            b_x = [item.to(device) for item in b_x]\n",
    "            b_y = [{key: values.to(device) for key, values in target.items()} for target in b_y]\n",
    "            output=model(b_x)\n",
    "            if(output[0]['labels'].size()[0] > 0):\n",
    "                if(output[0]['labels'][0] == b_y[0]['labels'][0]):\n",
    "                    n+=1\n",
    "    return n/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### CAR ######\n",
    "model.train()\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "num_epochs = 16\n",
    "train_acc = []\n",
    "evaluate_acc = []\n",
    "train_avg_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    n=0\n",
    "    train_loss = []\n",
    "    for i,(b_x, b_y) in enumerate(dataloaded):\n",
    "        model.train()\n",
    "        b_x = [item.to(device) for item in b_x]\n",
    "        b_y = [{key: values.to(device) for key, values in target.items()} for target in b_y]\n",
    "        loss_dict = model(b_x,b_y)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(losses.item())\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(b_x)\n",
    "            if(output[0]['labels'].size()[0] > 0):\n",
    "                if(output[0]['labels'][0] == b_y[0]['labels'][0]):\n",
    "                    n+=1\n",
    "        if(i%100 == 0):\n",
    "            print(losses)\n",
    "    train_avg_loss.append(sum(train_loss)/len(train_loss))\n",
    "    evaluate_acc.append(evaluate_model(model,dataloaded_tot_eval))\n",
    "    train_acc.append(n/(8144))\n",
    "    lr_scheduler.step()\n",
    "    print(\"epoch: {}\\t train_avg_loss: {}\\t train_acc: {}\\t evaluation_acc: {}\\n\".format(epoch,train_avg_loss[epoch],train_acc[epoch],evaluate_acc[epoch]))\n",
    "    torch.save(model.state_dict(), \"models/Model_epoch_{}\".format(epoch))\n",
    "with open('acc_data.txt', 'w') as f:\n",
    "    for i in range(len(train_avg_loss)):\n",
    "        f.write(\"{}\\t{}\\t{}\\n\".format(train_avg_loss[i],train_acc[i],evaluate_acc[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 0\t train_avg_loss: 0.09698943298310042\t train_acc: 0.98\t evaluation_acc: 1.0\n",
      "\n",
      "tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 1\t train_avg_loss: 0.05489407739291589\t train_acc: 1.0\t evaluation_acc: 0.96\n",
      "\n",
      "tensor(0.0349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 2\t train_avg_loss: 0.04112678675912321\t train_acc: 1.0\t evaluation_acc: 0.94\n",
      "\n",
      "tensor(0.0417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 3\t train_avg_loss: 0.032444785377010704\t train_acc: 1.0\t evaluation_acc: 0.94\n",
      "\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 4\t train_avg_loss: 0.029602673538029194\t train_acc: 1.0\t evaluation_acc: 0.94\n",
      "\n",
      "tensor(0.0254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 5\t train_avg_loss: 0.027543710355336468\t train_acc: 1.0\t evaluation_acc: 0.94\n",
      "\n",
      "tensor(0.0182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 6\t train_avg_loss: 0.026338201900944113\t train_acc: 1.0\t evaluation_acc: 0.94\n",
      "\n",
      "tensor(0.0240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 7\t train_avg_loss: 0.02598532580770552\t train_acc: 1.0\t evaluation_acc: 0.94\n",
      "\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 8\t train_avg_loss: 0.025677899184326333\t train_acc: 1.0\t evaluation_acc: 0.94\n",
      "\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 9\t train_avg_loss: 0.025562862052271762\t train_acc: 1.0\t evaluation_acc: 0.94\n",
      "\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 10\t train_avg_loss: 0.024944963607316215\t train_acc: 1.0\t evaluation_acc: 0.94\n",
      "\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 11\t train_avg_loss: 0.02511420739814639\t train_acc: 1.0\t evaluation_acc: 0.94\n",
      "\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 12\t train_avg_loss: 0.025583611293695865\t train_acc: 1.0\t evaluation_acc: 0.94\n",
      "\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 13\t train_avg_loss: 0.024907819611641267\t train_acc: 1.0\t evaluation_acc: 0.94\n",
      "\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 14\t train_avg_loss: 0.02482502834716191\t train_acc: 1.0\t evaluation_acc: 0.94\n",
      "\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 15\t train_avg_loss: 0.024883516182502112\t train_acc: 1.0\t evaluation_acc: 0.94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###### License plate ########\n",
    "\n",
    "#model_LP.train()\n",
    "\n",
    "#params = [p for p in model_LP.parameters() if p.requires_grad]\n",
    "#optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "#lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "#num_epochs = 1\n",
    "#for epoch in range(num_epochs):\n",
    "#    for i,(b_x, b_y) in enumerate(dataloaded_LP):\n",
    "#        b_x = [item.to(device) for item in b_x]\n",
    "#        b_y = [{key: values.to(device) for key, values in target.items()} for target in b_y]\n",
    "#        loss_dict=model_LP(b_x,b_y)\n",
    "#        losses = sum(loss for loss in loss_dict.values())\n",
    "#        optimizer.zero_grad()\n",
    "#        losses.backward()\n",
    "#        optimizer.step()\n",
    "#        if(i%10 == 0):\n",
    "#            print(losses)\n",
    "#    lr_scheduler.step()\n",
    "#    print(epoch)\n",
    "\n",
    "#save_model_LP = False\n",
    "#if(save_model_LP):\n",
    "#    torch.save(model_LP.state_dict(), \"Model_1\")\n",
    "    \n",
    "model_LP.train()\n",
    "params = [p for p in model_LP.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "num_epochs = 16\n",
    "train_acc = []\n",
    "evaluate_acc = []\n",
    "train_avg_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    n=0\n",
    "    train_loss = []\n",
    "    for i,(b_x, b_y) in enumerate(dataloaded_LP):\n",
    "        model_LP.train()\n",
    "        b_x = [item.to(device) for item in b_x]\n",
    "        b_y = [{key: values.to(device) for key, values in target.items()} for target in b_y]\n",
    "        loss_dict = model_LP(b_x,b_y)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(losses.item())\n",
    "        model_LP.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model_LP(b_x)\n",
    "            if(output[0]['labels'].size()[0] > 0):\n",
    "                if(output[0]['labels'][0] == b_y[0]['labels'][0]):\n",
    "                    n+=1\n",
    "        if(i%40 == 0):\n",
    "            print(losses)\n",
    "    train_avg_loss.append(sum(train_loss)/len(train_loss))\n",
    "    evaluate_acc.append(evaluate_model(model_LP,dataloaded_LP_eval))\n",
    "    train_acc.append(n/(300))\n",
    "    lr_scheduler.step()\n",
    "    print(\"epoch: {}\\t train_avg_loss: {}\\t train_acc: {}\\t evaluation_acc: {}\\n\".format(epoch,train_avg_loss[epoch],train_acc[epoch],evaluate_acc[epoch]))\n",
    "    torch.save(model_LP.state_dict(), \"models/Model_epoch_LP_{}\".format(epoch))\n",
    "with open('acc_data_LP.txt', 'w') as f:\n",
    "    for i in range(len(train_avg_loss)):\n",
    "        f.write(\"{}\\t{}\\t{}\\n\".format(train_avg_loss[i],train_acc[i],evaluate_acc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### Tot set ######\n",
    "\n",
    "model_tot.train()\n",
    "\n",
    "params = [p for p in model_tot.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "num_epochs = 1\n",
    "train_acc = []\n",
    "evaluate_acc = []\n",
    "train_avg_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    n=0\n",
    "    train_loss = []\n",
    "    for i,(b_x, b_y) in enumerate(dataloaded_tot):\n",
    "        model_tot.train()\n",
    "        b_x = [item.to(device) for item in b_x]\n",
    "        b_y = [{key: values.to(device) for key, values in target.items()} for target in b_y]\n",
    "        loss_dict = model_tot(b_x,b_y)\n",
    "        model_tot.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model_tot(b_x)\n",
    "            if(output[0]['labels'].size()[0] > 0):\n",
    "                if(output[0]['labels'][0] == b_y[0]['labels'][0]):\n",
    "                    n+=1\n",
    "        model_tot.train()\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(losses.item())\n",
    "        if(i%100 == 0):\n",
    "            print(losses)\n",
    "    train_avg_loss.append(sum(train_loss)/len(train_loss))\n",
    "    evaluate_acc.append(evaluate_model(model_tot,dataloaded_tot_eval))\n",
    "    train_acc.append(n/(8144+433))\n",
    "    lr_scheduler.step()\n",
    "    print(\"epoch: {}\\t train_avg_loss: {}\\t train_acc: {}\\t evaluation_acc: {}\\n\".format(epoch,train_avg_loss[epoch],train_acc[epoch],evaluate_acc[epoch]))\n",
    "    torch.save(model_tot.state_dict(), \"models/Model_tot_epoch_{}\".format(epoch))\n",
    "\n",
    "with open('acc_data_tot.txt', 'w') as f:\n",
    "    for i in range(len(train_avg_loss)):\n",
    "        f.write(\"{}\\t{}\\t{}\\n\".format(train_avg_loss[i],train_acc[i],evaluate_acc[epoch]))\n",
    "save_model_tot = False\n",
    "if(save_model_LP):\n",
    "    torch.save(model_tot.state_dict(), \"Model_tot_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_avg_loss.append(evaluate_model(model_tot,dataloaded_tot_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_names  = open(\"class_names.txt\", \"r\").read().split(\"\\t\")\n",
    "\n",
    "def eval_and_plot_image(model, df, indx,plot_image=False, plate_on_cars = False):\n",
    "    model = model.eval()\n",
    "    image, target = df[indx]\n",
    "    images = torch.stack([image]+[image]).to(device)\n",
    "    with torch.no_grad():\n",
    "        out=model(images)\n",
    "    if(plot_image):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(image.permute(1, 2, 0))\n",
    "        boxes=[]\n",
    "        box = out[0]['boxes'][0]\n",
    "        width=(box[2]-box[0])\n",
    "        height=(box[3]-box[1])\n",
    "        \n",
    "    keep = torchvision.ops.nms(out[0]['boxes'], out[0]['scores'], 0.2)\n",
    "    license_indxes = []\n",
    "    car_indxes = []\n",
    "    keep_final = []\n",
    "    license_belong = torch.ones([len(out[0]['boxes'])])\n",
    "    for indx in keep:\n",
    "        if out[0]['labels'][indx] == 197 and out[0]['scores'][indx] > 0.2:\n",
    "            license_indxes.append(indx)\n",
    "        elif out[0]['labels'][indx] != 197 and out[0]['scores'][indx] > 0.1:\n",
    "            keep_going = True\n",
    "            car_indxes.append(indx)        \n",
    "            keep_final.append(indx)\n",
    "    \n",
    "    \n",
    "    ids = 0\n",
    "    if plate_on_cars and 197 in out[0]['labels'] and len(keep)>1:\n",
    "        for license_indx in license_indxes:\n",
    "            keep_license = False\n",
    "            for car_indx in car_indxes:\n",
    "\n",
    "                if out[0]['boxes'][car_indx][0] < out[0]['boxes'][license_indx][0] and out[0]['boxes'][car_indx][2] > out[0]['boxes'][license_indx][2] and out[0]['boxes'][car_indx][1] < out[0]['boxes'][license_indx][1] and out[0]['boxes'][car_indx][3] > out[0]['boxes'][license_indx][3]:\n",
    "                    ids += 1\n",
    "                    license_belong[license_indx] = ids\n",
    "                    license_belong[car_indx] = ids\n",
    "                    keep_license = True\n",
    "                    \n",
    "\n",
    "            if keep_license:\n",
    "                keep_final.append(license_indx) \n",
    "                        \n",
    "    \n",
    "                    \n",
    "        \n",
    "            \n",
    "\n",
    "    for indx in keep_final:\n",
    "        s = \"Car: {:.0f}, Label: {}, score: {score:.2f}\".format(license_belong[indx],class_names[out[0]['labels'][indx]-1],score=out[0]['scores'][indx])\n",
    "        if(plot_image):\n",
    "            width=(out[0]['boxes'][indx][2]-out[0]['boxes'][indx][0])\n",
    "            height=(out[0]['boxes'][indx][3]-out[0]['boxes'][indx][1])\n",
    "            ax.add_patch(Rectangle((out[0]['boxes'][indx][0],out[0]['boxes'][indx][1]),width,height,fill = False, edgecolor = \"green\"))\n",
    "            ax.text(out[0]['boxes'][indx][0],out[0]['boxes'][indx][1],s,color = \"red\", size = 'small', fontweight = 'bold', horizontalalignment='left')\n",
    "\n",
    "\n",
    "eval_and_plot_image(model_tot, dataset_tot, 8144+71, True, True) #8144+71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#eval_and_plot_image(model, dataset, 29,True)\n",
    "indices=[]\n",
    "for i in range(100):        \n",
    "    lab = eval_and_plot_image(model_tot, dataset_tot, i)\n",
    "    indices.append(lab)\n",
    "with open('50proc_tot_small.txt', 'w') as f:\n",
    "    for item in indices:\n",
    "        f.write(\"{}\\n\".format(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_and_plot_image(model_tot, dataset_tot, 4, True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.dom.minidom\n",
    "def get_BB_xml(path):\n",
    "    document = xml.dom.minidom.parse(path)\n",
    "    x1 = document.getElementsByTagName(\"xmin\")[0]\n",
    "    x1=x1.childNodes[0]\n",
    "    x1=x1.nodeValue\n",
    "    y1 = document.getElementsByTagName(\"ymin\")[0]\n",
    "    y1=y1.childNodes[0]\n",
    "    y1=y1.nodeValue\n",
    "    x2 = document.getElementsByTagName(\"xmax\")[0]\n",
    "    x2=x2.childNodes[0]\n",
    "    x2=x2.nodeValue\n",
    "    y2 = document.getElementsByTagName(\"ymax\")[0]\n",
    "    y2=y2.childNodes[0]\n",
    "    y2=y2.nodeValue\n",
    "    return torch.tensor([float(x1),float(y1),float(x2),float(y2)],dtype=torch.float32)\n",
    "bbox=[]\n",
    "for i in range(433):\n",
    "    bbox.append(get_BB_xml(\"LPtrain/annotations/Cars{}.xml\".format(i)))\n",
    "with open('lp_bb.txt', 'w') as f:\n",
    "    for item in bbox:\n",
    "        f.write(\"{}\\t{}\\t{}\\t{}\\n\".format(item[0],item[1],item[2],item[3]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SCORE TEST SET #####\n",
    "def score_model(model, dataset, indx):\n",
    "    model = model.eval()\n",
    "    image, target = dataset[indx]\n",
    "    images = torch.stack([image]+[image]).to(device)\n",
    "    with torch.no_grad():\n",
    "        out=model(images)\n",
    "        keep = torchvision.ops.nms(out[0]['boxes'], out[0]['scores'], 0.1)\n",
    "        for indx in keep:\n",
    "            if(target['labels'][0].to(device) == out[0]['labels'][indx]):# or out[0]['labels'][indx] == 197:\n",
    "                return 1\n",
    "    return 0\n",
    "score=0           \n",
    "for i in range(100):   \n",
    "    score+=score_model(model_tot,dataset_tot_test,i)\n",
    "print(score/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
